# -*- coding: utf-8 -*-
"""music_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19AMuLMz5FnD8-5ewMQdK6NlTZ67MwgKB

# EDA
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
plt.style.use('ggplot') 
pd.set_option('max_columns',200)

df = pd.read_csv("music_genre.csv")



# top 5 row in the dataset
df.head()

#how many number of columns and  row
df.shape

#All columns name
df.columns

#All columns name
df.columns

df.describe()

sns.set(rc={'figure.figsize':(30,6)})

# Create box plot
sns.boxplot(data=df)

# Show plot
plt.show()

#Check for missing value
df.isna().sum()

df= df.dropna()

# from sklearn.preprocessing import LabelEncoder

# le = LabelEncoder()
# df['GENDER'] = le.fit_transform(df['GENDER'])
# df['LUNG_CANCER'] = le.fit_transform(df['LUNG_CANCER'])

df.dtypes

df.head()

#convert categorical columns to numbers
# df = port
from sklearn.preprocessing import LabelEncoder

# Create a label encoder object
le = LabelEncoder()

# Iterate over all the values of each column and extract their dtypes
for col in df:
    if df[col].dtype=='object':
        # Use the label encoder object to fit_transform
        df[col]=le.fit_transform(df[col])

df.head()

df.dtypes

df = df.dropna()

df_corr = df[['instance_id', 'artist_name', 'track_name', 'popularity',
       'acousticness', 'danceability', 'duration_ms', 'energy',
       'instrumentalness', 'key', 'liveness', 'loudness', 'mode',
       'speechiness', 'tempo', 'obtained_date', 'valence', 'music_genre']].corr()
df_corr

plt.figure(figsize = (16,10), dpi=200)
ax = plt.axes()
sns.heatmap(df.corr(), annot = True, cmap='RdBu', ax=ax)
ax.set_title('Correlation Matrix - Before Encoding & Handling Missing Data', weight='bold')
plt.show()

columns = ['key','mode','tempo']
for column in columns:
    print(df[column].unique())

def preprocess_inputs(df):
    df = df.copy()
    
    df = df.drop(['instance_id','artist_name','track_name','obtained_date'],axis=1)

    df['mode'] = df['mode'].replace({'Minor' : 0,
                                     'Major' : 1})

    embarked_dummies = pd.get_dummies(df.key)
    df = pd.concat([df, embarked_dummies], axis=1)
    df = df.drop('key',axis=1)
    
    df['tempo'] = df['tempo'].replace('?',np.nan)
    df["tempo"] = df["tempo"].astype("float")
    df['tempo'] = df['tempo'].fillna(df['tempo'].mean())
     
    df['music_genre'] = df['music_genre'].replace({'Electronic':0, 'Anime':1, 'Jazz':2, 'Alternative':3, 'Country':4, 'Rap':5,
                                                   'Blues':5, 'Rock':6, 'Classical':7, 'Hip-Hop':8})    
    
    y = df['music_genre']
    X = df.drop('music_genre',axis=1)
    
    X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.7, shuffle=True, random_state=43)
    
    scaler = StandardScaler()
    scaler.fit(X_train)
    
    X_train = pd.DataFrame(scaler.transform(X_train), index = X_train.index, columns = X_train.columns)
    X_test = pd.DataFrame(scaler.transform(X_test), index = X_test.index, columns = X_test.columns)
    
    return X_train, X_test, y_train, y_test

"""# DT"""

import pandas as pd
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score

# Split the data into features and labels
X = df.drop('music_genre', axis=1)
y = df['music_genre']

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
# train, test, labels_train, labels_test = sklearn.model_selection.train_test_split(iris.data, iris.target, train_size=0.80)

# Define the Decision Tree model
dt = DecisionTreeClassifier()

# Train the Decision Tree model
dt.fit(X_train, y_train)

# Make predictions on the test set
y_pred_dt = dt.predict(X_test)

# Evaluation using accuracy score
acc_dt = accuracy_score(y_test, y_pred_dt)
print("Decision Tree Accuracy:", acc_dt)

# Evaluation using confusion matrix
confusion_matrix_dt = confusion_matrix(y_test, y_pred_dt)
print("Decision Tree Confusion Matrix:")
print(confusion_matrix_dt)

# Evaluation using classification report
print("Decision Tree classification report:")
print(classification_report(y_test, y_pred_dt))

# input_data = np.array([1,69,1,2,2,1,1,2,1,2,2,2,2,2,2]).reshape(1,-1)
# prediction = dt.predict(input_data)

# prediction

!pip install lime
import lime
import lime.lime_tabular
from __future__ import print_function
np.random.seed(1)

df.columns
X=df[['instance_id', 'artist_name', 'track_name', 'popularity',
       'acousticness', 'danceability', 'duration_ms', 'energy',
       'instrumentalness', 'key', 'liveness', 'loudness', 'mode',
       'speechiness', 'tempo', 'obtained_date', 'valence']]



explainer = lime.lime_tabular.LimeTabularExplainer(X.values, feature_names=df.columns.values.tolist(), class_names=['NO LUNG CANCER','LUNG CANCER'], verbose=True, mode='classification')

j = 22
exp = explainer.explain_instance(X.values[j], dt.predict_proba, num_features=15, top_labels=1)
exp

exp.show_in_notebook(show_table=True)



"""# Hybrid Model"""

# Use the decision tree to select the most important features from the training data
important_features = dt.feature_importances_
X_train_important = X_train.iloc[:, important_features > 0]
X_test_important = X_test.iloc[:, important_features > 0]

# Train a neural network on the selected features
nn = MLPClassifier()
nn.fit(X_train_important, y_train)

# Make predictions on the test set using the neural network
y_pred_nn = nn.predict(X_test_important)

# Calculate the accuracy of the hybrid model
accuracy = accuracy_score(y_test, y_pred_nn)
print("Accuracy:", accuracy)

# Evaluation using accuracy score
acc_nn = accuracy_score(y_test, y_pred_nn)
print("Hybrid Model Accuracy:", acc_nn)

# Evaluation using confusion matrix
confusion_matrix_nn = confusion_matrix(y_test, y_pred_nn)
print("Hybrid Model Confusion Matrix:")
print(confusion_matrix_nn)

# Evaluation using classification report
print("Hybrid Model report:")
print(classification_report(y_test, y_pred_nn))

explainer = lime.lime_tabular.LimeTabularExplainer(X_train_important.values, feature_names=df.columns.values.tolist(), class_names=['NO LUNG CANCER','LUNG CANCER'], verbose=True, mode='classification')
# Select a random sample from the test set to explain
i = 21
exp = explainer.explain_instance(X_train_important.iloc[i, :], nn.predict_proba, num_features=14)

# Show the explanation
exp.show_in_notebook(show_table=True, show_all=False)

import xgboost as xgb
from sklearn.metrics import accuracy_score

# Split data into training and test sets
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create XGBoost data matrices
dtrain = xgb.DMatrix(data=X_train, label=y_train)
dtest = xgb.DMatrix(data=X_test, label=y_test)

# Set XGBoost parameters
params = {'objective': 'binary:logistic', 'eval_metric': 'error'}

# Train the model
model = xgb.train(params=params, dtrain=dtrain, num_boost_round=100)

# Predict on the test set
y_pred = model.predict(dtest)

# Convert predictions to binary labels
y_pred = [round(pred) for pred in y_pred]

# Calculate accuracy
acc = accuracy_score(y_test, y_pred)

# Print accuracy
print("Accuracy: ", acc)